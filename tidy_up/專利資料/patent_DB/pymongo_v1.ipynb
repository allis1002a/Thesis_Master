{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "# from sshtunnel import SSHTunnelForwarder\n",
    "import pymongo\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongoURI = \"mongodb://%s:%s@%s/%s?authMechanism=SCRAM-SHA-1\" % (\"M094020060\", \"s45nds43\", \"140.117.69.70:30241\", \"Allison\")\n",
    " \n",
    "try:\n",
    "    conn = pymongo.MongoClient(mongoURI)\n",
    "    db = conn.Allison\n",
    "    db_patents = db.All_Innovation_patents\n",
    "except errors.ConnectionFailure as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.read_csv('firm_clean_V2.csv')\n",
    "comp_list = list(comp['cp_name']) \n",
    "df1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patent總數 -10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/allis/Desktop/論文/資料集/dataset/tidy_up/專利資料/patent_DB/pymongo_v1.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allis/Desktop/%E8%AB%96%E6%96%87/%E8%B3%87%E6%96%99%E9%9B%86/dataset/tidy_up/%E5%B0%88%E5%88%A9%E8%B3%87%E6%96%99/patent_DB/pymongo_v1.ipynb#ch0000005?line=0'>1</a>\u001b[0m data_try\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allis/Desktop/%E8%AB%96%E6%96%87/%E8%B3%87%E6%96%99%E9%9B%86/dataset/tidy_up/%E5%B0%88%E5%88%A9%E8%B3%87%E6%96%99/patent_DB/pymongo_v1.ipynb#ch0000005?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m comp \u001b[39min\u001b[39;00m comp_list:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/allis/Desktop/%E8%AB%96%E6%96%87/%E8%B3%87%E6%96%99%E9%9B%86/dataset/tidy_up/%E5%B0%88%E5%88%A9%E8%B3%87%E6%96%99/patent_DB/pymongo_v1.ipynb#ch0000005?line=3'>4</a>\u001b[0m     data_us_cp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(db_patents\u001b[39m.\u001b[39;49maggregate(pipeline\u001b[39m=\u001b[39;49m[{\u001b[39m'\u001b[39;49m\u001b[39m$unwind\u001b[39;49m\u001b[39m'\u001b[39;49m:{\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39m$original_assignee\u001b[39;49m\u001b[39m'\u001b[39;49m}},\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allis/Desktop/%E8%AB%96%E6%96%87/%E8%B3%87%E6%96%99%E9%9B%86/dataset/tidy_up/%E5%B0%88%E5%88%A9%E8%B3%87%E6%96%99/patent_DB/pymongo_v1.ipynb#ch0000005?line=4'>5</a>\u001b[0m     {\u001b[39m'\u001b[39;49m\u001b[39m$match\u001b[39;49m\u001b[39m'\u001b[39;49m : { \u001b[39m'\u001b[39;49m\u001b[39moriginal_assignee\u001b[39;49m\u001b[39m'\u001b[39;49m:{\u001b[39m\"\u001b[39;49m\u001b[39m$regex\u001b[39;49m\u001b[39m\"\u001b[39;49m:comp}}}]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/allis/Desktop/%E8%AB%96%E6%96%87/%E8%B3%87%E6%96%99%E9%9B%86/dataset/tidy_up/%E5%B0%88%E5%88%A9%E8%B3%87%E6%96%99/patent_DB/pymongo_v1.ipynb#ch0000005?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(comp)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/allis/Desktop/%E8%AB%96%E6%96%87/%E8%B3%87%E6%96%99%E9%9B%86/dataset/tidy_up/%E5%B0%88%E5%88%A9%E8%B3%87%E6%96%99/patent_DB/pymongo_v1.ipynb#ch0000005?line=9'>10</a>\u001b[0m     data_try\u001b[39m=\u001b[39mdata_try\u001b[39m.\u001b[39mappend(data_us_cp,ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pandas/core/frame.py:710\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pandas/core/frame.py?line=707'>708</a>\u001b[0m         data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(data)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pandas/core/frame.py?line=708'>709</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pandas/core/frame.py?line=709'>710</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(data)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pandas/core/frame.py?line=710'>711</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pandas/core/frame.py?line=711'>712</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_dataclass(data[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py:274\u001b[0m, in \u001b[0;36mCommandCursor.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=271'>272</a>\u001b[0m \u001b[39m# Block until a document is returnable.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=272'>273</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malive:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=273'>274</a>\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_next(\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=274'>275</a>\u001b[0m     \u001b[39mif\u001b[39;00m doc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=275'>276</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py:285\u001b[0m, in \u001b[0;36mCommandCursor._try_next\u001b[0;34m(self, get_more_allowed)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=282'>283</a>\u001b[0m \u001b[39m\"\"\"Advance the cursor blocking for at most one getMore command.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=283'>284</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__data) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__killed \u001b[39mand\u001b[39;00m get_more_allowed:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=284'>285</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_refresh()\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=285'>286</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__data):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=286'>287</a>\u001b[0m     coll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__collection\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py:212\u001b[0m, in \u001b[0;36mCommandCursor._refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=209'>210</a>\u001b[0m     dbname, collname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__ns\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=210'>211</a>\u001b[0m     read_pref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__collection\u001b[39m.\u001b[39m_read_preference_for(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=211'>212</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__send_message(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=212'>213</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getmore_class(dbname,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=213'>214</a>\u001b[0m                             collname,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=214'>215</a>\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__batch_size,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=215'>216</a>\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__id,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=216'>217</a>\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__collection\u001b[39m.\u001b[39;49mcodec_options,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=217'>218</a>\u001b[0m                             read_pref,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=218'>219</a>\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__session,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=219'>220</a>\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__collection\u001b[39m.\u001b[39;49mdatabase\u001b[39m.\u001b[39;49mclient,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=220'>221</a>\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__max_await_time_ms,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=221'>222</a>\u001b[0m                             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__sock_mgr, \u001b[39mFalse\u001b[39;49;00m))\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=222'>223</a>\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Cursor id is zero nothing else to return\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=223'>224</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__die(\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py:158\u001b[0m, in \u001b[0;36mCommandCursor.__send_message\u001b[0;34m(self, operation)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=155'>156</a>\u001b[0m client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__collection\u001b[39m.\u001b[39mdatabase\u001b[39m.\u001b[39mclient\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=156'>157</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=157'>158</a>\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49m_run_operation(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=158'>159</a>\u001b[0m         operation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unpack_response, address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__address)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=159'>160</a>\u001b[0m \u001b[39mexcept\u001b[39;00m OperationFailure \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=160'>161</a>\u001b[0m     \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39mcode \u001b[39min\u001b[39;00m _CURSOR_CLOSED_ERRORS:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/command_cursor.py?line=161'>162</a>\u001b[0m         \u001b[39m# Don't send killCursors because the cursor is already closed.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py:1424\u001b[0m, in \u001b[0;36mMongoClient._run_operation\u001b[0;34m(self, operation, unpack_res, address)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1418'>1419</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cmd\u001b[39m(session, server, sock_info, secondary_ok):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1419'>1420</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m server\u001b[39m.\u001b[39mrun_operation(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1420'>1421</a>\u001b[0m         sock_info, operation, secondary_ok, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_listeners,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1421'>1422</a>\u001b[0m         unpack_res)\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1423'>1424</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retryable_read(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1424'>1425</a>\u001b[0m     _cmd, operation\u001b[39m.\u001b[39;49mread_preference, operation\u001b[39m.\u001b[39;49msession,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1425'>1426</a>\u001b[0m     address\u001b[39m=\u001b[39;49maddress, retryable\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(operation, message\u001b[39m.\u001b[39;49m_Query))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py:1525\u001b[0m, in \u001b[0;36mMongoClient._retryable_read\u001b[0;34m(self, func, read_pref, session, address, retryable)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1520'>1521</a>\u001b[0m         \u001b[39mif\u001b[39;00m retrying \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m retryable:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1521'>1522</a>\u001b[0m             \u001b[39m# A retry is not possible because this server does\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1522'>1523</a>\u001b[0m             \u001b[39m# not support retryable reads, raise the last error.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1523'>1524</a>\u001b[0m             \u001b[39mraise\u001b[39;00m last_error\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1524'>1525</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(session, server, sock_info, secondary_ok)\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1525'>1526</a>\u001b[0m \u001b[39mexcept\u001b[39;00m ServerSelectionTimeoutError:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1526'>1527</a>\u001b[0m     \u001b[39mif\u001b[39;00m retrying:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1527'>1528</a>\u001b[0m         \u001b[39m# The application may think the write was never attempted\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1528'>1529</a>\u001b[0m         \u001b[39m# if we raise ServerSelectionTimeoutError on the retry\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1529'>1530</a>\u001b[0m         \u001b[39m# attempt. Raise the original exception instead.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py:1420\u001b[0m, in \u001b[0;36mMongoClient._run_operation.<locals>._cmd\u001b[0;34m(session, server, sock_info, secondary_ok)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1418'>1419</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cmd\u001b[39m(session, server, sock_info, secondary_ok):\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1419'>1420</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m server\u001b[39m.\u001b[39;49mrun_operation(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1420'>1421</a>\u001b[0m         sock_info, operation, secondary_ok, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_listeners,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/mongo_client.py?line=1421'>1422</a>\u001b[0m         unpack_res)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/server.py:114\u001b[0m, in \u001b[0;36mServer.run_operation\u001b[0;34m(self, sock_info, operation, set_secondary_okay, listeners, unpack_res)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/server.py?line=111'>112</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/server.py?line=112'>113</a>\u001b[0m     sock_info\u001b[39m.\u001b[39msend_message(data, max_doc_size)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/server.py?line=113'>114</a>\u001b[0m     reply \u001b[39m=\u001b[39m sock_info\u001b[39m.\u001b[39;49mreceive_message(request_id)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/server.py?line=115'>116</a>\u001b[0m \u001b[39m# Unpack and check for command errors.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/server.py?line=116'>117</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cmd:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py:753\u001b[0m, in \u001b[0;36mSocketInfo.receive_message\u001b[0;34m(self, request_id)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=750'>751</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m receive_message(\u001b[39mself\u001b[39m, request_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_message_size)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=751'>752</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=752'>753</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_connection_failure(error)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py:751\u001b[0m, in \u001b[0;36mSocketInfo.receive_message\u001b[0;34m(self, request_id)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=745'>746</a>\u001b[0m \u001b[39m\"\"\"Receive a raw BSON message or raise ConnectionFailure.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=746'>747</a>\u001b[0m \n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=747'>748</a>\u001b[0m \u001b[39mIf any exception is raised, the socket is closed.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=748'>749</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=749'>750</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=750'>751</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m receive_message(\u001b[39mself\u001b[39;49m, request_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_message_size)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=751'>752</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/pool.py?line=752'>753</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_connection_failure(error)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py:219\u001b[0m, in \u001b[0;36mreceive_message\u001b[0;34m(sock_info, request_id, max_message_size)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=214'>215</a>\u001b[0m     data \u001b[39m=\u001b[39m decompress(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=215'>216</a>\u001b[0m         _receive_data_on_socket(sock_info, length \u001b[39m-\u001b[39m \u001b[39m25\u001b[39m, deadline),\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=216'>217</a>\u001b[0m         compressor_id)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=217'>218</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=218'>219</a>\u001b[0m     data \u001b[39m=\u001b[39m _receive_data_on_socket(sock_info, length \u001b[39m-\u001b[39;49m \u001b[39m16\u001b[39;49m, deadline)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=220'>221</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=221'>222</a>\u001b[0m     unpack_reply \u001b[39m=\u001b[39m _UNPACK_REPLY[op_code]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py:291\u001b[0m, in \u001b[0;36m_receive_data_on_socket\u001b[0;34m(sock_info, length, deadline)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=288'>289</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=289'>290</a>\u001b[0m     wait_for_read(sock_info, deadline)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=290'>291</a>\u001b[0m     chunk_length \u001b[39m=\u001b[39m sock_info\u001b[39m.\u001b[39;49msock\u001b[39m.\u001b[39;49mrecv_into(mv[bytes_read:])\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=291'>292</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/essay/lib/python3.8/site-packages/pymongo/network.py?line=292'>293</a>\u001b[0m     \u001b[39mif\u001b[39;00m _errno_from_exception(exc) \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mEINTR:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_try= pd.DataFrame()\n",
    "\n",
    "for comp in comp_list:\n",
    "    data_us_cp = pd.DataFrame(db_patents.aggregate(pipeline=[{'$unwind':{'path':'$original_assignee'}},\n",
    "    {'$match' : { 'original_assignee':{\"$regex\":comp}}}]))\n",
    "\n",
    "    print(comp)\n",
    "    \n",
    "\n",
    "    data_try=data_try.append(data_us_cp,ignore_index=True)\n",
    "\n",
    "data_try.to_csv('cp_patents_All_V2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patent總數 --全部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International Business Machines Corp\n",
      "Netease Inc\n",
      "Perion Network Ltd\n",
      "Yelp Inc\n",
      "Digital Turbine Inc\n",
      "Automatic Data Processing Inc\n",
      "PDF Solutions Inc\n",
      "Absolute Software Corp\n",
      "Aware Inc.\n",
      "Open Text Corp\n",
      "Crexendo Inc\n",
      "Microsoft Corp\n",
      "ServiceSource International Inc\n",
      "Cornerstone OnDemand Inc\n",
      "Verisign Inc\n",
      "Yandex NV\n",
      "Oracle Corp\n",
      "MicroStrategy Inc\n",
      "Brightcove Inc\n",
      "BlackBerry Ltd\n",
      "Bottomline Technologies Inc\n",
      "NetScout Systems Inc\n",
      "SAP SE\n",
      "Teradata Corporation\n",
      "Cadence Design Systems Inc\n",
      "Immersion Corp\n",
      "Renren Inc\n",
      "NextGen Healthcare Inc\n",
      "eGain Corp\n",
      "Electronic Arts Inc\n",
      "01 Communique Laboratory Inc\n",
      "Aspen Technology Inc\n",
      "Intuit Inc.\n",
      "NICE Ltd\n",
      "eBay Inc.\n",
      "Descartes Systems Group Inc (The)\n",
      "Tyler Technologies Inc\n",
      "Enghouse Systems Ltd\n",
      "Proofpoint Inc\n",
      "Trend Micro Inc\n",
      "Shutterstock Inc\n",
      "Qumu Corp\n",
      "Unisys Corp\n",
      "TECSYS Inc\n",
      "Intrusion Inc\n",
      "Palo Alto Networks Inc\n",
      "American Software Inc\n",
      "Optiva Inc\n",
      "PASSUR Aerospace Inc\n",
      "AUTODESK INC\n",
      "F5 Inc\n",
      "ACI Worldwide Inc\n",
      "SPS Commerce Inc\n",
      "SeaChange International Inc\n",
      "Ribbon Communications Inc\n",
      "Activision Blizzard Inc\n",
      "salesforce.com Inc\n",
      "CSG Systems International Inc.\n",
      "Infosys Ltd\n",
      "Nuance Communications Inc\n",
      "Zynga Inc\n",
      "Verint Systems Inc\n",
      "NCR Corp\n",
      "NortonLifeLock Inc\n",
      "ServiceNow Inc\n",
      "CoStar Group Inc\n",
      "Pegasystems Inc\n",
      "CYREN Ltd\n",
      "Cerner Corp\n",
      "Ziff Davis Inc\n",
      "Counterpath Corp\n",
      "Alphabet Inc\n",
      "Adobe Inc\n",
      "VIQ Solutions Inc\n",
      "Dassault Systemes SA\n",
      "RealPage Inc\n",
      "Amdocs Ltd\n",
      "Limelight Networks Inc\n",
      "ANSYS Inc\n",
      "Baidu Inc\n",
      "Match Group Inc\n",
      "GRAVITY Co Ltd\n",
      "Synchronoss Technologies Inc\n",
      "Meta Platforms Inc\n",
      "PTC Inc\n",
      "Blackbaud Inc\n",
      "Smith Micro Software Inc\n",
      "AKAMAI TECHNOLOGIES INC\n",
      "Citrix Systems Inc\n",
      "SuperCom Ltd\n",
      "Omnicell Inc\n",
      "Net 1 Ueps Technologies Inc\n",
      "Stamps.com Inc\n",
      "Kratos Defense & Security Solutions Inc\n",
      "Synacor Inc\n",
      "Elbit Systems Ltd\n",
      "Leaf Group Ltd\n",
      "Radcom Ltd\n",
      "Check Point Software Technologies Ltd\n",
      "HealthStream Inc\n",
      "Glu Mobile Inc\n",
      "Synopsys Inc\n",
      "Evolving Systems Inc\n",
      "Manhattan Associates Inc\n",
      "CSP Inc\n",
      "SS&C Technologies Holdings Inc\n",
      "iSign Solutions Inc\n",
      "MobileSmith Inc\n",
      "Zix Corp.\n",
      "RealNetworks Inc\n",
      "LivePerson Inc\n",
      "hopTo Inc\n",
      "Progress Software Corp\n",
      "CommVault Systems Inc\n",
      "comScore Inc\n",
      "Fujitsu Ltd\n",
      "Telos Corp/MD\n",
      "Guidewire Software Inc\n",
      "ImageWare Systems Inc.\n",
      "QAD Inc\n"
     ]
    }
   ],
   "source": [
    "data_All= pd.DataFrame()\n",
    "\n",
    "for comp in comp_list:\n",
    "    data_us_cp = pd.DataFrame(db_patents.aggregate(pipeline=[{'$unwind':{'path':'$original_assignee'}},\n",
    "    {'$match' : { 'original_assignee':{\"$regex\":comp}}}]))\n",
    "\n",
    "    print(comp)\n",
    "    \n",
    "\n",
    "    data_All=data_All.append(data_us_cp,ignore_index=True)\n",
    "\n",
    "\n",
    "data_All.to_csv('cp_patents_All.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抓cited數量-全部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International Business Machines Corp\n",
      "Netease Inc\n",
      "Perion Network Ltd\n",
      "Yelp Inc\n",
      "Digital Turbine Inc\n",
      "Automatic Data Processing Inc\n",
      "PDF Solutions Inc\n",
      "Absolute Software Corp\n",
      "Aware Inc.\n",
      "Open Text Corp\n",
      "Crexendo Inc\n",
      "Microsoft Corp\n",
      "ServiceSource International Inc\n",
      "Cornerstone OnDemand Inc\n",
      "Verisign Inc\n",
      "Yandex NV\n",
      "Oracle Corp\n",
      "MicroStrategy Inc\n",
      "Brightcove Inc\n",
      "BlackBerry Ltd\n",
      "Bottomline Technologies Inc\n",
      "NetScout Systems Inc\n",
      "SAP SE\n",
      "Teradata Corporation\n",
      "Cadence Design Systems Inc\n",
      "Immersion Corp\n",
      "Renren Inc\n",
      "NextGen Healthcare Inc\n",
      "eGain Corp\n",
      "Electronic Arts Inc\n",
      "01 Communique Laboratory Inc\n",
      "Aspen Technology Inc\n",
      "Intuit Inc.\n",
      "NICE Ltd\n",
      "eBay Inc.\n",
      "Descartes Systems Group Inc (The)\n",
      "Tyler Technologies Inc\n",
      "Enghouse Systems Ltd\n",
      "Proofpoint Inc\n",
      "Trend Micro Inc\n",
      "Shutterstock Inc\n",
      "Qumu Corp\n",
      "Unisys Corp\n",
      "TECSYS Inc\n",
      "Intrusion Inc\n",
      "Palo Alto Networks Inc\n",
      "American Software Inc\n",
      "Optiva Inc\n",
      "PASSUR Aerospace Inc\n",
      "AUTODESK INC\n",
      "F5 Inc\n",
      "ACI Worldwide Inc\n",
      "SPS Commerce Inc\n",
      "SeaChange International Inc\n",
      "Ribbon Communications Inc\n",
      "Activision Blizzard Inc\n",
      "salesforce.com Inc\n",
      "CSG Systems International Inc.\n",
      "Infosys Ltd\n",
      "Nuance Communications Inc\n",
      "Zynga Inc\n",
      "Verint Systems Inc\n",
      "NCR Corp\n",
      "NortonLifeLock Inc\n",
      "ServiceNow Inc\n",
      "CoStar Group Inc\n",
      "Pegasystems Inc\n",
      "CYREN Ltd\n",
      "Cerner Corp\n",
      "Ziff Davis Inc\n",
      "Counterpath Corp\n",
      "Alphabet Inc\n",
      "Adobe Inc\n",
      "VIQ Solutions Inc\n",
      "Dassault Systemes SA\n",
      "RealPage Inc\n",
      "Amdocs Ltd\n",
      "Limelight Networks Inc\n",
      "ANSYS Inc\n",
      "Baidu Inc\n",
      "Match Group Inc\n",
      "GRAVITY Co Ltd\n",
      "Synchronoss Technologies Inc\n",
      "Meta Platforms Inc\n",
      "PTC Inc\n",
      "Blackbaud Inc\n",
      "Smith Micro Software Inc\n",
      "AKAMAI TECHNOLOGIES INC\n",
      "Citrix Systems Inc\n",
      "SuperCom Ltd\n",
      "Omnicell Inc\n",
      "Net 1 Ueps Technologies Inc\n",
      "Stamps.com Inc\n",
      "Kratos Defense & Security Solutions Inc\n",
      "Synacor Inc\n",
      "Elbit Systems Ltd\n",
      "Leaf Group Ltd\n",
      "Radcom Ltd\n",
      "Check Point Software Technologies Ltd\n",
      "HealthStream Inc\n",
      "Glu Mobile Inc\n",
      "Synopsys Inc\n",
      "Evolving Systems Inc\n",
      "Manhattan Associates Inc\n",
      "CSP Inc\n",
      "SS&C Technologies Holdings Inc\n",
      "iSign Solutions Inc\n",
      "MobileSmith Inc\n",
      "Zix Corp.\n",
      "RealNetworks Inc\n",
      "LivePerson Inc\n",
      "hopTo Inc\n",
      "Progress Software Corp\n",
      "CommVault Systems Inc\n",
      "comScore Inc\n",
      "Fujitsu Ltd\n",
      "Telos Corp/MD\n",
      "Guidewire Software Inc\n",
      "ImageWare Systems Inc.\n",
      "QAD Inc\n"
     ]
    }
   ],
   "source": [
    "data_cited_all=pd.DataFrame()\n",
    "\n",
    "for comp in comp_list:\n",
    "    d1 = pd.DataFrame(db_patents.aggregate(pipeline=[{'$project':{'original_assignee':1, 'appDate':1, 'cited':1}},\n",
    "        {'$unwind':'$original_assignee'},\n",
    "        {'$match' : { 'original_assignee':{\"$regex\":comp}}},\n",
    "        {'$unwind':'$cited'}\n",
    "        # {'$group': {\n",
    "        #     '_id': \"$original_assignee\",\n",
    "        #     'count':{\n",
    "        #         '$sum':1\n",
    "        #         }\n",
    "        #     }\n",
    "        # },\n",
    "        # {\"$limit\":10000}\n",
    "        ]))\n",
    "\n",
    "    print(comp)\n",
    "    data_cited_all=data_cited_all.append(d1,ignore_index=True)\n",
    "\n",
    "data_cited_all.to_csv('data_cited_All.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抓bk_citation-全部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International Business Machines Corp\n",
      "Netease Inc\n",
      "Perion Network Ltd\n",
      "Yelp Inc\n",
      "Digital Turbine Inc\n",
      "Automatic Data Processing Inc\n",
      "PDF Solutions Inc\n",
      "Absolute Software Corp\n",
      "Aware Inc.\n",
      "Open Text Corp\n",
      "Crexendo Inc\n",
      "Microsoft Corp\n",
      "ServiceSource International Inc\n",
      "Cornerstone OnDemand Inc\n",
      "Verisign Inc\n",
      "Yandex NV\n",
      "Oracle Corp\n",
      "MicroStrategy Inc\n",
      "Brightcove Inc\n",
      "BlackBerry Ltd\n",
      "Bottomline Technologies Inc\n",
      "NetScout Systems Inc\n",
      "SAP SE\n",
      "Teradata Corporation\n",
      "Cadence Design Systems Inc\n",
      "Immersion Corp\n",
      "Renren Inc\n",
      "NextGen Healthcare Inc\n",
      "eGain Corp\n",
      "Electronic Arts Inc\n",
      "01 Communique Laboratory Inc\n",
      "Aspen Technology Inc\n",
      "Intuit Inc.\n",
      "NICE Ltd\n",
      "eBay Inc.\n",
      "Descartes Systems Group Inc (The)\n",
      "Tyler Technologies Inc\n",
      "Enghouse Systems Ltd\n",
      "Proofpoint Inc\n",
      "Trend Micro Inc\n",
      "Shutterstock Inc\n",
      "Qumu Corp\n",
      "Unisys Corp\n",
      "TECSYS Inc\n",
      "Intrusion Inc\n",
      "Palo Alto Networks Inc\n",
      "American Software Inc\n",
      "Optiva Inc\n",
      "PASSUR Aerospace Inc\n",
      "AUTODESK INC\n",
      "F5 Inc\n",
      "ACI Worldwide Inc\n",
      "SPS Commerce Inc\n",
      "SeaChange International Inc\n",
      "Ribbon Communications Inc\n",
      "Activision Blizzard Inc\n",
      "salesforce.com Inc\n",
      "CSG Systems International Inc.\n",
      "Infosys Ltd\n",
      "Nuance Communications Inc\n",
      "Zynga Inc\n",
      "Verint Systems Inc\n",
      "NCR Corp\n",
      "NortonLifeLock Inc\n",
      "ServiceNow Inc\n",
      "CoStar Group Inc\n",
      "Pegasystems Inc\n",
      "CYREN Ltd\n",
      "Cerner Corp\n",
      "Ziff Davis Inc\n",
      "Counterpath Corp\n",
      "Alphabet Inc\n",
      "Adobe Inc\n",
      "VIQ Solutions Inc\n",
      "Dassault Systemes SA\n",
      "RealPage Inc\n",
      "Amdocs Ltd\n",
      "Limelight Networks Inc\n",
      "ANSYS Inc\n",
      "Baidu Inc\n",
      "Match Group Inc\n",
      "GRAVITY Co Ltd\n",
      "Synchronoss Technologies Inc\n",
      "Meta Platforms Inc\n",
      "PTC Inc\n",
      "Blackbaud Inc\n",
      "Smith Micro Software Inc\n",
      "AKAMAI TECHNOLOGIES INC\n",
      "Citrix Systems Inc\n",
      "SuperCom Ltd\n",
      "Omnicell Inc\n",
      "Net 1 Ueps Technologies Inc\n",
      "Stamps.com Inc\n",
      "Kratos Defense & Security Solutions Inc\n",
      "Synacor Inc\n",
      "Elbit Systems Ltd\n",
      "Leaf Group Ltd\n",
      "Radcom Ltd\n",
      "Check Point Software Technologies Ltd\n",
      "HealthStream Inc\n",
      "Glu Mobile Inc\n",
      "Synopsys Inc\n",
      "Evolving Systems Inc\n",
      "Manhattan Associates Inc\n",
      "CSP Inc\n",
      "SS&C Technologies Holdings Inc\n",
      "iSign Solutions Inc\n",
      "MobileSmith Inc\n",
      "Zix Corp.\n",
      "RealNetworks Inc\n",
      "LivePerson Inc\n",
      "hopTo Inc\n",
      "Progress Software Corp\n",
      "CommVault Systems Inc\n",
      "comScore Inc\n",
      "Fujitsu Ltd\n",
      "Telos Corp/MD\n",
      "Guidewire Software Inc\n",
      "ImageWare Systems Inc.\n",
      "QAD Inc\n"
     ]
    }
   ],
   "source": [
    "data_bk_citation_all=pd.DataFrame()\n",
    "\n",
    "for comp in comp_list:\n",
    "    bk_citation_all = pd.DataFrame(db_patents.aggregate(pipeline=[{'$project':{'original_assignee':1, 'appDate':1, 'patentCitation':1}},\n",
    "        {'$unwind':'$original_assignee'},\n",
    "        {'$match' : { 'original_assignee':{\"$regex\":comp}}},\n",
    "        {'$unwind':'$patentCitation'}\n",
    "        # {'$group': {\n",
    "        #     '_id': \"$original_assignee\",\n",
    "        #     'count':{\n",
    "        #         '$sum':1\n",
    "        #         }\n",
    "        #     }\n",
    "        # },\n",
    "        # {\"$limit\":10000}\n",
    "        ]))\n",
    "\n",
    "    print(comp)\n",
    "    data_bk_citation_all=data_bk_citation_all.append(bk_citation_all,ignore_index=True)\n",
    "\n",
    "\n",
    "data_bk_citation_all.to_csv('data_bk_citation_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bk_citation-cpc -全部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International Business Machines Corp\n",
      "Netease Inc\n",
      "Perion Network Ltd\n",
      "Yelp Inc\n",
      "Digital Turbine Inc\n",
      "Automatic Data Processing Inc\n",
      "PDF Solutions Inc\n",
      "Absolute Software Corp\n",
      "Aware Inc\n",
      "Open Text Corp\n",
      "Crexendo Inc\n",
      "Microsoft Corp\n",
      "ServiceSource International Inc\n",
      "Cornerstone OnDemand Inc\n",
      "Verisign Inc\n",
      "Yandex NV\n",
      "Oracle Corp\n",
      "MicroStrategy Inc\n",
      "Brightcove Inc\n",
      "BlackBerry Ltd\n",
      "Bottomline Technologies Inc\n",
      "NetScout Systems Inc\n",
      "SAP SE\n",
      "Teradata Corporation\n",
      "Cadence Design Systems Inc\n",
      "Immersion Corp\n",
      "Renren Inc\n",
      "NextGen Healthcare Inc\n",
      "eGain Corp\n",
      "Electronic Arts Inc\n",
      "01 Communique Laboratory Inc\n",
      "Aspen Technology Inc\n",
      "Intuit Inc\n",
      "NICE Ltd\n",
      "eBay Inc\n",
      "Descartes Systems Group Inc The\n",
      "Tyler Technologies Inc\n",
      "Enghouse Systems Ltd\n",
      "Proofpoint Inc\n",
      "Trend Micro Inc\n",
      "Shutterstock Inc\n",
      "Qumu Corp\n",
      "Unisys Corp\n",
      "TECSYS Inc\n",
      "Intrusion Inc\n",
      "Palo Alto Networks Inc\n",
      "American Software Inc\n",
      "Optiva Inc\n",
      "PASSUR Aerospace Inc\n",
      "AUTODESK INC\n",
      "F5 Inc\n",
      "ACI Worldwide Inc\n",
      "SPS Commerce Inc\n",
      "SeaChange International Inc\n",
      "Ribbon Communications Inc\n",
      "Activision Blizzard Inc\n",
      "salesforcecom Inc\n",
      "CSG Systems International Inc\n",
      "Infosys Ltd\n",
      "Nuance Communications Inc\n",
      "Zynga Inc\n",
      "Verint Systems Inc\n",
      "NCR Corp\n",
      "NortonLifeLock Inc\n",
      "ServiceNow Inc\n",
      "CoStar Group Inc\n",
      "Pegasystems Inc\n",
      "CYREN Ltd\n",
      "Cerner Corp\n",
      "Ziff Davis Inc\n",
      "Counterpath Corp\n",
      "Alphabet Inc\n",
      "Adobe Inc\n",
      "VIQ Solutions Inc\n",
      "Dassault Systemes SA\n",
      "RealPage Inc\n",
      "Amdocs Ltd\n",
      "Limelight Networks Inc\n",
      "ANSYS Inc\n",
      "Baidu Inc\n",
      "Match Group Inc\n",
      "GRAVITY Co Ltd\n",
      "Synchronoss Technologies Inc\n",
      "Meta Platforms Inc\n",
      "PTC Inc\n",
      "Blackbaud Inc\n",
      "Smith Micro Software Inc\n",
      "AKAMAI TECHNOLOGIES INC\n",
      "Citrix Systems Inc\n",
      "SuperCom Ltd\n",
      "Omnicell Inc\n",
      "Net 1 Ueps Technologies Inc\n",
      "Stampscom Inc\n",
      "Kratos Defense  Security Solutions Inc\n",
      "Synacor Inc\n",
      "Elbit Systems Ltd\n",
      "Leaf Group Ltd\n",
      "Radcom Ltd\n",
      "Check Point Software Technologies Ltd\n",
      "HealthStream Inc\n",
      "Glu Mobile Inc\n",
      "Synopsys Inc\n",
      "Evolving Systems Inc\n",
      "Manhattan Associates Inc\n",
      "CSP Inc\n",
      "SSC Technologies Holdings Inc\n",
      "iSign Solutions Inc\n",
      "MobileSmith Inc\n",
      "Zix Corp\n",
      "RealNetworks Inc\n",
      "LivePerson Inc\n",
      "hopTo Inc\n",
      "Progress Software Corp\n",
      "CommVault Systems Inc\n",
      "comScore Inc\n",
      "Fujitsu Ltd\n",
      "Telos CorpMD\n",
      "Guidewire Software Inc\n",
      "ImageWare Systems Inc\n",
      "QAD Inc\n"
     ]
    }
   ],
   "source": [
    "data_bk_cpc_all=pd.DataFrame()\n",
    "\n",
    "for comp in comp_list:\n",
    "\n",
    "    bk_cpc_all = pd.DataFrame(db_patents.aggregate(pipeline=[{'$project':{'original_assignee':1, 'appDate':1, 'patentCitation':1}},\n",
    "        {'$unwind':'$original_assignee'},\n",
    "        {'$match' : { 'original_assignee':{\"$regex\":comp}}},\n",
    "        {'$unwind':'$patentCitation'},\n",
    "        {'$unwind':'$patentCitation.classification'}\n",
    "        # {'$group': {\n",
    "        #     '_id': \"$original_assignee\",\n",
    "        #     'count':{\n",
    "        #         '$sum':1\n",
    "        #         }\n",
    "        #     }\n",
    "        # },\n",
    "        # {\"$limit\":10000}\n",
    "        ]))\n",
    "\n",
    "    print(comp)\n",
    "    data_bk_cpc_all=data_bk_cpc_all.append(bk_cpc_all,ignore_index=True)\n",
    "\n",
    "data_bk_cpc_all.to_csv('data_bk_cpc_all_V2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_us_cp = pd.DataFrame(db_patents.aggregate(pipeline=[{'$unwind':{'path':'$original_assignee'}},\n",
    "#  { '$match' : { 'original_assignee':{\"$regex\":rgx}}} ,\n",
    "#  {\"$limit\":10000}\n",
    "# ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_company = []\n",
    "ls_count = []\n",
    "data_assignee = pd.DataFrame()\n",
    "for c in comp_list:\n",
    "\n",
    "    data = pd.DataFrame(db_patents.find([\n",
    "        {\"$limit\":10000},\n",
    "        # {'$project' : { 'cp_many' : { '$split': [\"$original_as\", ', '] }, \"qty\":1,\"description\": 1  } },\n",
    "        {\"$unwind\" : \"$original_as\"}\n",
    "        # {\"$match\" : {\"cp_many\":{\"$regex\":c}}},# 用like\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {\"$project\" : {\"class\": {\"$split\": [\"$classification\", \"/\"]}, \"qty\":1}},\n",
    "\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {\"$group\" : {\"_id\" : \"$cp_many\", \"count\":{\"$sum\":1}}},\n",
    "        # {\"$sort\": {\"count\":-1}},\n",
    "        # {\"$limit\":10}\n",
    "    ]))\n",
    "    data_assignee=data_assignee.append(data,ignore_index=True)\n",
    "\n",
    "    # for data in data_assignee:\n",
    "    #     # print(data[\"_id\"])\n",
    "    #     ls_company.append(data[\"_id\"])\n",
    "    #     ls_count.append(data[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MONGO_HOST = '140.117.69.70'\n",
    "MONGO_DB = 'Allison'\n",
    "MONGO_COLLETION = 'All_Innovation_patents'\n",
    "\n",
    "#   http://www.twse.com.tw/exchangeReport/STOCK_DAY?date=20180817&stockNo=2330\n",
    "\n",
    "def connect_mongo():  #連線資料庫\n",
    "    global collection\n",
    "    client = MongoClient(MONGO_HOST, 30241)\n",
    "    db = client[MONGO_DB]\n",
    "    collection = db[MONGO_COLLETION]\n",
    "    print(\"目前存在的DB有  \",client.list_database_names())\n",
    "    print(\"目前存在的collection有  \",db.list_collection_names())\n",
    "\n",
    "connect_mongo()  #呼叫連線資料庫函式\n",
    "\n",
    "\n",
    "# query = { 'stockno' : '2892' }\n",
    "# cursor = collection.find(query)  #依query查詢資料\n",
    "# stock =  pd.DataFrame(list(cursor))  #轉換成DataFrame\n",
    "# del stock['_id']  #刪除欄位_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 每間公司專利權總數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.read_csv('firm_clean.csv')\n",
    "comp_list = list(comp['cp_name']) #\n",
    "myquery = { \"_id\": 0, \"original_as\": comp_list, \"description\": 1 , 'pubDate' : 1, \"cited\" : 1, \"patentCitat\" : 1}\n",
    "df1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_company = []\n",
    "ls_count = []\n",
    "data_assignee = pd.DataFrame()\n",
    "for c in comp_list:\n",
    "\n",
    "    data = pd.DataFrame(collection.aggregate([\n",
    "        # {\"$limit\":10000},\n",
    "        {'$project' : { 'cp_many' : { '$split': [\"$original_as\", ', '] }, \"qty\":1,\"description\": 1  } },\n",
    "        {\"$unwind\" : \"$cp_many\"},\n",
    "        {\"$match\" : {\"cp_many\":{\"$regex\":c}}},# 用like\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {\"$project\" : {\"class\": {\"$split\": [\"$classification\", \"/\"]}, \"qty\":1}},\n",
    "\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {\"$group\" : {\"_id\" : \"$cp_many\", \"count\":{\"$sum\":1}}},\n",
    "        # {\"$sort\": {\"count\":-1}},\n",
    "        # {\"$limit\":10}\n",
    "    ]))\n",
    "    data_assignee=data_assignee.append(data,ignore_index=True)\n",
    "\n",
    "    # for data in data_assignee:\n",
    "    #     # print(data[\"_id\"])\n",
    "    #     ls_company.append(data[\"_id\"])\n",
    "    #     ls_count.append(data[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assignee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assignee.to_csv('description_80000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.read_csv('firm_clean.csv')\n",
    "comp_list = list(comp['cp_name']) #\n",
    "myquery = { \"_id\": 0, \"original_as\": comp_list, \"description\": 1 , 'pubDate' : 1, \"cited\" : 1, \"patentCitat\" : 1}\n",
    "df1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_company = []\n",
    "ls_count = []\n",
    "data_assignee = pd.DataFrame()\n",
    "for c in comp_list:\n",
    "\n",
    "    data = pd.DataFrame(collection.aggregate([\n",
    "        {'$project' : { 'cp_many' : { '$split': [\"$original_as\", ', '] }, \"qty\":1} },\n",
    "        {\"$unwind\" : \"$cp_many\"},\n",
    "        {\"$match\" : {\"cp_many\":{\"$regex\":c}}},# 用like\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {\"$project\" : {\"class\": {\"$split\": [\"$classification\", \"/\"]}, \"qty\":1}},\n",
    "\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        {\"$group\" : {\"_id\" : \"$cp_many\", \"count\":{\"$sum\":1}}},\n",
    "        {\"$sort\": {\"count\":-1}},\n",
    "        # {\"$limit\":10}\n",
    "    ]))\n",
    "    data_assignee=data_assignee.append(data,ignore_index=True)\n",
    "\n",
    "    # for data in data_assignee:\n",
    "    #     # print(data[\"_id\"])\n",
    "    #     ls_company.append(data[\"_id\"])\n",
    "    #     ls_count.append(data[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assignee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assignee['new_name'] =  ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 整理格式不一樣的公司名\n",
    "# re.search('[A-Za-z]', c)\n",
    "import re\n",
    "# dd = \"重出123江湖hello的地方的,world\"\n",
    "for dd in range(len(data_assignee['_id'])):\n",
    "    data_assignee['new_name'][dd] = ''.join(re.findall(r'[A-Za-z]', data_assignee['_id'][dd]))\n",
    "    data_assignee['new_name'][dd] = re.sub('CitrixSystemsIncFtLauderdaleFl', 'CitrixSystemsInc', data_assignee['new_name'][dd]) \n",
    "    data_assignee['new_name'][dd] = re.sub('InternationalBusinessMachinesCorporation', 'InternationalBusinessMachinesCorp', data_assignee['new_name'][dd]) \n",
    "    data_assignee['new_name'][dd] = re.sub('MicrosoftCorporation', 'MicrosoftCorp', data_assignee['new_name'][dd])\n",
    "    data_assignee['new_name'][dd] = re.sub('OpenTextCorporation', 'OpenTextCorp', data_assignee['new_name'][dd])\n",
    "    data_assignee['new_name'][dd] = re.sub('UnisysCorporation', 'UnisysCorp', data_assignee['new_name'][dd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_group = data_assignee.groupby(['new_name'])\n",
    "cp_group = pd.DataFrame(job_group['count'].aggregate(['min', 'max', 'mean', 'median','sum']))\n",
    "\n",
    "# data_assignee.aggregate(['sum', 'min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_group_v1 = cp_group.reset_index(drop=False)\n",
    "cp_group_v1.to_csv('cp_group_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_group_v1 #78家公司; fuji相同 待更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_company = []\n",
    "ls_count = []\n",
    "data_cited = pd.DataFrame()\n",
    "for c in comp_list:\n",
    "\n",
    "    data = pd.DataFrame(collection.aggregate([\n",
    "        {'$project' : { 'cp_many' : { '$split': [\"$original_as\", ', '] }, \"qty\":1, 'cited' : '$cited' } },\n",
    "        {\"$unwind\" : \"$cp_many\"},\n",
    "        {\"$unwind\" : \"$cited\"},\n",
    "        {\"$match\" : {\"cp_many\":{\"$regex\":c}}},\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {\"$project\" : {\"class\": {\"$split\": [\"$cited\", \", \"]}, \"qty\":1}},\n",
    "\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {\"$group\" : {\"_id\" : \"$class\", \"count\":{\"$sum\":1}}},\n",
    "        # {\"$sort\": {\"count\":-1}},\n",
    "        # {\"$limit\":10}\n",
    "    ]))\n",
    "    data_cited_v2=data_cited.append(data,ignore_index=True)\n",
    "\n",
    "    for data in data_assignee:\n",
    "        # print(data[\"_id\"])\n",
    "        ls_company.append(data[\"_id\"])\n",
    "        ls_count.append(data[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cited_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_company = []\n",
    "ls_count = []\n",
    "data_cited = pd.DataFrame()\n",
    "for c in comp_list:\n",
    "\n",
    "    data = pd.DataFrame(collection.aggregate([\n",
    "\n",
    "        {'$project' : { 'cited_num' : { '$split': [\"$cited\", ', '] }, \"qty\":1} },\n",
    "        # {\"$limit\":100},\n",
    "        {\"$unwind\" : \"$cited_num\"},\n",
    "        # {\"$match\" : {\"cited_num\":{\"$regex\":c}}},\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {\"$project\" : {\"class\": {\"$split\": [\"$classification\", \"/\"]}, \"qty\":1}},\n",
    "\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        {\"$group\" : {\"_id\" : \"$cited_num\", \"count\":{\"$sum\":1}}},\n",
    "        # {\"$sort\": {\"count\":-1}}\n",
    "\n",
    "    ]))\n",
    "    data_cited=data_cited.append(data,ignore_index=True)\n",
    "\n",
    "    # for data in data_assignee:\n",
    "    #     # print(data[\"_id\"])\n",
    "    #     ls_company.append(data[\"_id\"])\n",
    "    #     ls_count.append(data[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_company = []\n",
    "ls_count = []\n",
    "data_assignee = pd.DataFrame()\n",
    "for c in comp_list:\n",
    "\n",
    "    data = pd.DataFrame(collection.aggregate([\n",
    "        {'$project' : { 'cp_many' : { '$split': [\"$original_as\", ', '] }, \"qty\":1, 'year': {'$dateFromString': {format: \"%Y\", 'date':'$pubDate' }} }},\n",
    "        {\"$unwind\" : \"$cp_many\"},\n",
    "        {\"$match\" : {\"cp_many\":{\"$regex\":c}}},# 用like\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {\"$project\" : {\"class\": {\"$split\": [\"$classification\", \"/\"]}, \"qty\":1}},\n",
    "\n",
    "        # {\"$unwind\" : \"$cp_many\"},\n",
    "        # {'$group': {'_id': { 'year': {'$dateFromString': { 'dateString': \"$pubDate\", format: \"%Y/%m/%d\" }},'total_cost_month': { '$sum': \"$total_cost\" }}}},\n",
    "        # {\"$group\" : {\"_id\" : {\"$pubDate\" : { format: \"%Y-%m-%d\", 'date': \"$date\" }}, \"count\":{\"$sum\":1}}},\n",
    "        # {'$addFields': { 'date' : { '$sum': \"$count.sum\" }}},\n",
    "        {\"$sort\": {\"count\":-1}},\n",
    "        # {\"$limit\":10}\n",
    "    ]))\n",
    "    data_assignee=data_assignee.append(data,ignore_index=True)\n",
    "\n",
    "    # for data in data_assignee:\n",
    "    #     # print(data[\"_id\"])\n",
    "    #     ls_company.append(data[\"_id\"])\n",
    "    #     ls_count.append(data[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAP_2000 = df1.sort_values('pubDate',ascending=True)  # 排序\n",
    "SAP_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up our imports\n",
    "\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "import numpy\n",
    "from gensim.matutils import hellinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAP_2000['Date']= pd.to_datetime(SAP_2000['pubDate'])\n",
    "SAP_2000_Date = SAP_2000.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAP_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAP_2000.to_csv('SAP_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAP_2000_Date\n",
    "SAP_2000_Date['2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAP_2000[SAP_2000['appDate']=='20151231'] #找各年度的index,為的是幫忙切"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAP_2000.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAP_2000_corpus = SAP_2000['description'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assignee = db_de.aggregate([\n",
    "    {\"$unwind\" : \"$current_assignee\"},\n",
    "    {\"$group\" : {\"_id\" : \"$current_assignee\", \"count\":{\"$sum\":1}}},\n",
    "    {\"$sort\": {\"count\":-1}}\n",
    "    # {\"$limit\":10}\n",
    "])\n",
    "\n",
    "ls_company = []\n",
    "ls_count = []\n",
    "for data in data_assignee:\n",
    "    #print(data[\"_id\"])\n",
    "    ls_company.append(data[\"_id\"])\n",
    "    ls_count.append(data[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pymongo CRUD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read/Find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find Query\n",
    "\n",
    "# first example\n",
    "# news = db.demoCollection.find().limit(3)\n",
    "\n",
    "# sencond xeample\n",
    "# news = db.demoCollection.find().limit(3).sort(\"your specific column\")\n",
    "\n",
    "# third example\n",
    "# d = datetime.datetime(2015, 12, 1)\n",
    "# news = db.demoCollection.find({\"artDate\":{\"$gt\":d}}).limit(3)\n",
    "\n",
    "news = News.find({\"dataSource\":\"appledaily新聞\"}).limit(3)\n",
    "print(news.count())\n",
    "for a_news in news:\n",
    "    print(a_news[\"artTitle\"])\n",
    "    print(a_news[\"artDate\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find_one Query\n",
    "\n",
    "only_one_news = News.find_one({\"dataSource\":\"appledaily新聞\"})\n",
    "print(only_one_news[\"artTitle\"])\n",
    "print(only_one_news[\"artDate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert Query\n",
    "\n",
    "# define python dict\n",
    "new_posts = [\n",
    "    {\"author\": \"Mike\",\n",
    "    \"artTitle\": \"Another post!\",\n",
    "    \"tags\": [\"bulk\", \"insert\"],\n",
    "    \"artDate\": datetime.datetime(2009, 11, 12, 11, 14)},\n",
    "    {\"author\": \"Eliot\",\n",
    "    \"artTitle\": \"MongoDB is fun\",\n",
    "    \"artContent\": \"and pretty easy too!\",\n",
    "    \"artDate\": datetime.datetime(2009, 11, 10, 10, 45)}]\n",
    "\n",
    "# inert into a new collection\n",
    "results = News.insert_many(new_posts)\n",
    "print(results.inserted_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Update \n",
    "#### 1. update field (not array)\n",
    "\n",
    "newData = {\n",
    "    \"text\":\"I update this article.\",\n",
    "}\n",
    "\n",
    "News.update_one(\n",
    "    {\"author\":\"Mike\"},\n",
    "    {\"$set\": newData}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. update array field (insert one element)\n",
    "\n",
    "newData = {\"tags\":\"new tag\"}\n",
    "\n",
    "News.update_one(\n",
    "    {\"author\":\"Mike\"},\n",
    "    {\"$push\": newData}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Delete\n",
    "\n",
    "News.delete_one({\"author\":\"Mike\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 刪除所有 “2015-12-14” 這一天的資料\n",
    " \n",
    "date1 = datetime.datetime(2015, 12, 14, 0, 0)\n",
    "date2 = datetime.datetime(2015, 12, 14, 23, 59)\n",
    "News.delete_many({\"$and\":[{\"artDate\": {\"$gte\":date1}},{\"artDate\": {\"$lte\":date2}}]})\n",
    "#$and : 參數是一個list,裡面包了很多的dict,條件為符合全部的dict條件"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2606589fe37672a2267b1d84b6b15beef2e0ebe3bac4b265ab2463e74efd8641"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('essay')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
